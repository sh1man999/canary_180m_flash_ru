name: canary-180m-flash-finetune
num_workers: 18
batch_size: 128
fit: true
spl_tokens:
  model_dir: canary_flash_tokenizers/spl_tokens
  tokens:
  - translate
  - transcribe
  - en
  - es
  - de
  - fr
  - ru
  force_rebuild: false
model:
  sample_rate: 16000
  label_smoothing: 0.0
  use_loss_mask_for_prompt: false
  log_prediction: true
  prompt_format: canary2
  prompt_defaults:
  - role: user
    slots:
      decodercontext: ''
      source_lang: <|ru|>
      target_lang: <|ru|>
      emotion: <|emo:undefined|>
      pnc: <|pnc|>
      itn: <|noitn|>
      diarize: <|nodiarize|>
      timestamp: <|notimestamp|>
  - role: user_partial
    slots:
      decodercontext: ''
  model_defaults:
    asr_enc_hidden: 512
    lm_enc_hidden: 1024
    lm_dec_hidden: 1024
  train_ds:
    use_lhotse: true
    shuffle: true
    num_workers: ${num_workers}
    manifest_filepath: ./datasets/train_manifest.jsonl
    sample_rate: 16000
    use_bucketing: true
    shuffle_buffer_size: 10000
    num_buckets: 30
    bucket_duration_bins: [[2.808,17],[2.808,19],[2.808,21],[2.808,23],[2.808,34],[3.192,21],[3.192,23],[3.192,25],[3.192,27],[3.192,39],[3.456,22],[3.456,25],[3.456,27],[3.456,30],[3.456,39],[3.744,24],[3.744,27],[3.744,29],[3.744,32],[3.744,46],[3.96,26],[3.96,29],[3.96,31],[3.96,35],[3.96,50],[4.176,27],[4.176,30],[4.176,33],[4.176,36],[4.176,51],[4.392,29],[4.392,33],[4.392,36],[4.392,39],[4.392,53],[4.584,30],[4.584,33],[4.584,37],[4.584,40],[4.584,53],[4.788,32],[4.788,35],[4.788,39],[4.788,43],[4.788,59],[4.968,33],[4.968,37],[4.968,40],[4.968,45],[4.968,59],[5.148,34],[5.148,38],[5.148,41],[5.148,46],[5.148,60],[5.304,36],[5.304,39],[5.304,43],[5.304,46],[5.304,60],[5.496,37],[5.496,41],[5.496,45],[5.496,49],[5.496,65],[5.664,38],[5.664,42],[5.664,46],[5.664,50],[5.664,63],[5.808,40],[5.808,43],[5.808,47],[5.808,51],[5.808,70],[5.976,41],[5.976,45],[5.976,49],[5.976,53],[5.976,67],[6.156,42],[6.156,47],[6.156,50],[6.156,55],[6.156,68],[6.336,42],[6.336,47],[6.336,51],[6.336,55],[6.336,69],[6.504,45],[6.504,50],[6.504,53],[6.504,57],[6.504,70],[6.696,44],[6.696,49],[6.696,53],[6.696,58],[6.696,73],[6.864,46],[6.864,51],[6.864,54],[6.864,59],[6.864,72],[7.056,48],[7.056,52],[7.056,56],[7.056,61],[7.056,83],[7.236,49],[7.236,54],[7.236,58],[7.236,62],[7.236,76],[7.464,50],[7.464,55],[7.464,59],[7.464,63],[7.464,78],[7.728,52],[7.728,57],[7.728,60],[7.728,64],[7.728,85],[7.992,53],[7.992,57],[7.992,61],[7.992,66],[7.992,84],[8.304,54],[8.304,59],[8.304,63],[8.304,68],[8.304,93],[8.676,54],[8.676,59],[8.676,64],[8.676,69],[8.676,88],[9.24,56],[9.24,62],[9.24,66],[9.24,71],[9.24,89],[11.484,59],[11.484,65],[11.484,69],[11.484,74],[11.484,90]]
    bucket_batch_size: [237,237,230,230,216,210,204,204,204,192,192,186,186,186,175,175,175,170,170,160,170,165,165,160,150,159,154,154,154,140,150,150,146,142,133,142,142,138,138,130,138,134,134,130,122,130,126,126,126,116,124,124,124,121,114,122,119,119,119,112,116,116,116,112,108,112,112,112,109,106,109,109,109,106,99,109,106,106,103,100,103,103,103,100,97,100,100,95,95,95,95,95,95,95,92,95,95,92,92,89,92,92,92,89,86,89,89,89,86,81,89,86,86,84,82,84,84,82,82,77,82,82,80,80,75,80,78,78,76,74,76,76,74,74,70,72,72,70,70,68,68,68,68,66,64,54,54,54,52,52]
    text_field: text
    lang_field: target_lang
  validation_ds:
    use_lhotse: true
    shuffle: false
    num_workers: ${num_workers}
    pin_memory: true
    batch_size: ${batch_size}
    use_start_end_token: true
    use_bucketing: false
    manifest_filepath: ./datasets/validate_manifest.jsonl
    sample_rate: ${model.sample_rate}
    text_field: text
    lang_field: target_lang
  test_ds:
    use_lhotse: true
    shuffle: false
    num_workers: ${num_workers}
    pin_memory: true
    batch_size: ${batch_size}
    use_start_end_token: true
    use_bucketing: false
    manifest_filepath: ./datasets/test_manifest.jsonl
    sample_rate: ${model.sample_rate}
    text_field: text
    lang_field: target_lang
  tokenizer:
    dir: null
    type: agg
    langs:
      spl_tokens:
        dir: canary_flash_tokenizers/spl_tokens
        type: bpe
      ru:
        dir: canary_flash_tokenizers/ru
        type: bpe
      en:
        dir: canary_flash_tokenizers/en
        type: bpe
      fr:
        dir: canary_flash_tokenizers/fr
        type: bpe
      de:
        dir: canary_flash_tokenizers/de
        type: bpe
      es:
        dir: canary_flash_tokenizers/es
        type: bpe
    custom_tokenizer:
      _target_: nemo.collections.common.tokenizers.canary_tokenizer.CanaryTokenizer
      tokenizers: null
  preprocessor:
    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor
    sample_rate: 16000
    normalize: per_feature
    window_size: 0.025
    window_stride: 0.01
    window: hann
    features: 128
    n_fft: 512
    log: true
    frame_splicing: 1
    dither: 1.0e-05
    pad_to: 0
    pad_value: 0.0
  spec_augment:
    _target_: nemo.collections.asr.modules.SpectrogramAugmentation
    freq_masks: 2
    time_masks: 10
    freq_width: 27
    time_width: 0.05
  encoder:
    _target_: nemo.collections.asr.modules.ConformerEncoder
    feat_in: 128
    feat_out: -1
    n_layers: 17
    d_model: 512
    subsampling: dw_striding
    subsampling_factor: 8
    subsampling_conv_channels: 256
    causal_downsampling: false
    reduction: null
    reduction_position: null
    reduction_factor: 1
    ff_expansion_factor: 4
    self_attention_model: rel_pos
    n_heads: 8
    att_context_size:
    - -1
    - -1
    xscaling: false
    untie_biases: true
    pos_emb_max_len: 5000
    conv_kernel_size: 9
    conv_norm_type: batch_norm
    conv_context_size: null
    dropout: 0.1
    dropout_pre_encoder: 0.1
    dropout_emb: 0.0
    dropout_att: 0.1
  transf_encoder:
    _target_: nemo.collections.asr.modules.transformer.transformer_encoders.TransformerEncoder
    num_layers: 0
    hidden_size: 1024
    inner_size: 4096
    num_attention_heads: 8
    ffn_dropout: 0.1
    attn_score_dropout: 0.1
    attn_layer_dropout: 0.1
    mask_future: false
    pre_ln: true
    pre_ln_final_layer_norm: true
  transf_decoder:
    _target_: nemo.collections.asr.modules.transformer.get_nemo_transformer
    model_name: null
    pretrained: false
    encoder: null
    pre_ln_final_layer_norm: true
    config_dict:
      max_sequence_length: 1024
      num_token_types: 0
      embedding_dropout: 0.1
      learn_positional_encodings: false
      hidden_size: 1024
      inner_size: 4096
      num_layers: 4
      num_attention_heads: 8
      ffn_dropout: 0.1
      attn_score_dropout: 0.1
      attn_layer_dropout: 0.1
      hidden_act: relu
      pre_ln: true
      vocab_size: None
  head:
    _target_: nemo.collections.asr.parts.submodules.token_classifier.TokenClassifier
    num_layers: 1
    activation: relu
    log_softmax: true
    hidden_size: ${model.transf_decoder.config_dict.hidden_size}
    num_classes: None
    dropout: 0.0
    use_transformer_init: true
  decoding:
    strategy: beam
    return_best_hypothesis: true
    beam:
      beam_size: 1
      len_pen: 0.0
      max_generation_delta: 50
  loss:
    _target_: nemo.collections.common.losses.smoothed_cross_entropy.SmoothedCrossEntropyLoss
    label_smoothing: ${model.label_smoothing}
    pad_id: null
  optim:
    name: adamw
    lr: 0.0003
    betas:
    - 0.9
    - 0.98
    weight_decay: 0.001
    sched:
      name: InverseSquareRootAnnealing
      warmup_steps: 2500
      warmup_ratio: null
      min_lr: 1.0e-06
trainer:
  devices: -1
  num_nodes: 1
  max_epochs: -1
  max_steps: 100000
  val_check_interval: 1.0
  accelerator: auto
  strategy:
    _target_: lightning.pytorch.strategies.DDPStrategy
    gradient_as_bucket_view: true
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  precision: bf16-mixed
  log_every_n_steps: 100
  enable_progress_bar: true
  num_sanity_val_steps: 2
  check_val_every_n_epoch: 1
  sync_batchnorm: true
  enable_checkpointing: false
  logger: false
  use_distributed_sampler: false
exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: val_loss
    mode: min
    save_top_k: 3
    always_save_nemo: true
  resume_from_checkpoint: null
  resume_if_exists: true
  resume_ignore_no_checkpoint: false
  create_wandb_logger: false
  wandb_logger_kwargs:
    name: null
    project: null
init_from_ptl_ckpt: "./models/last.ckpt"
