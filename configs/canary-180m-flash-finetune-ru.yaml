name: canary-180m-flash-finetune
num_workers: 8
batch_size: 64
fit: true
spl_tokens:
  model_dir: canary_flash_tokenizers/spl_tokens
  tokens:
  - translate
  - transcribe
  - en
  - es
  - de
  - fr
  - ru
  force_rebuild: false
model:
  sample_rate: 16000
  label_smoothing: 0.0
  use_loss_mask_for_prompt: false
  log_prediction: true
  prompt_format: canary2
  prompt_defaults:
  - role: user
    slots:
      decodercontext: ''
      source_lang: <|ru|>
      target_lang: <|ru|>
      emotion: <|emo:undefined|>
      pnc: <|pnc|>
      itn: <|noitn|>
      diarize: <|nodiarize|>
      timestamp: <|notimestamp|>
  - role: user_partial
    slots:
      decodercontext: ''
  model_defaults:
    asr_enc_hidden: 512
    lm_enc_hidden: 1024
    lm_dec_hidden: 1024
  train_ds:
    use_lhotse: true
    shuffle: true
    num_workers: ${num_workers}
    manifest_filepath: ./datasets/train_manifest.jsonl
    sample_rate: 16000
    batch_duration: 360
    quadratic_duration: 15
    use_bucketing: true
    bucket_buffer_size: 20000
    shuffle_buffer_size: 10000
    num_buckets: 20
    text_field: text
    lang_field: target_lang
  validation_ds:
    use_lhotse: true
    shuffle: false
    num_workers: ${num_workers}
    pin_memory: true
    batch_size: ${batch_size}
    use_start_end_token: true
    use_bucketing: false
    manifest_filepath: ./datasets/validate_manifest.jsonl
    sample_rate: ${model.sample_rate}
    text_field: text
    lang_field: target_lang
  test_ds:
    use_lhotse: true
    shuffle: false
    num_workers: ${num_workers}
    pin_memory: true
    batch_size: ${batch_size}
    use_start_end_token: true
    use_bucketing: false
    manifest_filepath: ./datasets/test_manifest.jsonl
    sample_rate: ${model.sample_rate}
    text_field: text
    lang_field: target_lang
  tokenizer:
    dir: null
    type: agg
    langs:
      spl_tokens:
        dir: canary_flash_tokenizers/spl_tokens
        type: bpe
      ru:
        dir: canary_flash_tokenizers/ru
        type: bpe
      en:
        dir: canary_flash_tokenizers/en
        type: bpe
      fr:
        dir: canary_flash_tokenizers/fr
        type: bpe
      de:
        dir: canary_flash_tokenizers/de
        type: bpe
      es:
        dir: canary_flash_tokenizers/es
        type: bpe
    custom_tokenizer:
      _target_: nemo.collections.common.tokenizers.canary_tokenizer.CanaryTokenizer
      tokenizers: null
  preprocessor:
    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor
    sample_rate: 16000
    normalize: per_feature
    window_size: 0.025
    window_stride: 0.01
    window: hann
    features: 128
    n_fft: 512
    log: true
    frame_splicing: 1
    dither: 1.0e-05
    pad_to: 0
    pad_value: 0.0
  spec_augment:
    _target_: nemo.collections.asr.modules.SpectrogramAugmentation
    freq_masks: 2
    time_masks: 10
    freq_width: 27
    time_width: 0.05
  encoder:
    _target_: nemo.collections.asr.modules.ConformerEncoder
    feat_in: 128
    feat_out: -1
    n_layers: 17
    d_model: 512
    subsampling: dw_striding
    subsampling_factor: 8
    subsampling_conv_channels: 256
    causal_downsampling: false
    reduction: null
    reduction_position: null
    reduction_factor: 1
    ff_expansion_factor: 4
    self_attention_model: rel_pos
    n_heads: 8
    att_context_size:
    - -1
    - -1
    xscaling: false
    untie_biases: true
    pos_emb_max_len: 5000
    conv_kernel_size: 9
    conv_norm_type: batch_norm
    conv_context_size: null
    dropout: 0.1
    dropout_pre_encoder: 0.1
    dropout_emb: 0.0
    dropout_att: 0.1
  transf_encoder:
    _target_: nemo.collections.asr.modules.transformer.transformer_encoders.TransformerEncoder
    num_layers: 0
    hidden_size: 1024
    inner_size: 4096
    num_attention_heads: 8
    ffn_dropout: 0.1
    attn_score_dropout: 0.1
    attn_layer_dropout: 0.1
    mask_future: false
    pre_ln: true
    pre_ln_final_layer_norm: true
  transf_decoder:
    _target_: nemo.collections.asr.modules.transformer.get_nemo_transformer
    model_name: null
    pretrained: false
    encoder: null
    pre_ln_final_layer_norm: true
    config_dict:
      max_sequence_length: 1024
      num_token_types: 0
      embedding_dropout: 0.1
      learn_positional_encodings: false
      hidden_size: 1024
      inner_size: 4096
      num_layers: 4
      num_attention_heads: 8
      ffn_dropout: 0.1
      attn_score_dropout: 0.1
      attn_layer_dropout: 0.1
      hidden_act: relu
      pre_ln: true
      vocab_size: None
  head:
    _target_: nemo.collections.asr.parts.submodules.token_classifier.TokenClassifier
    num_layers: 1
    activation: relu
    log_softmax: true
    hidden_size: ${model.transf_decoder.config_dict.hidden_size}
    num_classes: None
    dropout: 0.0
    use_transformer_init: true
  decoding:
    strategy: beam
    return_best_hypothesis: true
    beam:
      beam_size: 1
      len_pen: 0.0
      max_generation_delta: 50
  loss:
    _target_: nemo.collections.common.losses.smoothed_cross_entropy.SmoothedCrossEntropyLoss
    label_smoothing: ${model.label_smoothing}
    pad_id: null
  optim:
    name: adamw
    lr: 0.0003
    betas:
    - 0.9
    - 0.98
    weight_decay: 0.001
    sched:
      name: InverseSquareRootAnnealing
      warmup_steps: 2500
      warmup_ratio: null
      min_lr: 1.0e-06
trainer:
  devices: -1
  num_nodes: 1
  max_epochs: -1
  max_steps: 100000
  val_check_interval: 1.0
  accelerator: auto
  strategy:
    _target_: lightning.pytorch.strategies.DDPStrategy
    gradient_as_bucket_view: true
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  precision: bf16-mixed
  log_every_n_steps: 100
  enable_progress_bar: true
  num_sanity_val_steps: 2
  check_val_every_n_epoch: 1
  sync_batchnorm: true
  enable_checkpointing: false
  logger: false
  use_distributed_sampler: false
exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: val_loss
    mode: min
    save_top_k: 3
    always_save_nemo: true
  resume_from_checkpoint: null
  resume_if_exists: true
  resume_ignore_no_checkpoint: false
  create_wandb_logger: false
  wandb_logger_kwargs:
    name: null
    project: null